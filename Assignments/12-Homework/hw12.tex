\documentclass{article}

% packages for math
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}

% package for including images
\usepackage{graphicx}

% TAKEN FROM OVERLEAF DOCUMENTATION
% https://www.overleaf.com/learn/latex/Code_listing
\usepackage{listings}
\lstset{language=Python}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour},
  commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\footnotesize,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2
}
\lstset{style=mystyle}

% environment for solutions
\theoremstyle{remark}
\newtheorem*{solution}{Solution}

% capital letters for problem parts
\renewcommand{\theenumi}{\Alph{enumi}}

% no page numbers
\pagenumbering{gobble}

% UNCOMMENT IF YOU DON'T WANT PROBLEMS ON INDIVIDUAL PAGES
% \renewcommand{\pagebreak}{}

\newcommand{\vv}[1]{\mathbf{#1}}
\newcommand{\R}{\mathbb R}
\DeclareMathOperator{\vspan}{span}
\DeclareMathOperator{\cod}{cod}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\col}{Col}
\DeclareMathOperator{\nul}{Nul}
\DeclareMathOperator{\rank}{rank}

\title{
  Homework 12
}
\author{CAS CS 132: Geometric Algorithms}
\date{Due: \textbf{Tuesday December 12, 2023 at 11:59PM}}

\begin{document}
\maketitle

\subsection*{Submission Instructions}
This week there is only a programming assignment.
See below for instructions on submission to Gradescope.

\section*{Practice Problems}

The following list of problems comes from \textit{Linear Algebra and its Application 5th Ed} by David C.\ Lay, Steven R.\ Lay, and Judi J.\ McDonald.
They may be useful for solidifying your understanding of the material and for studying in general.
\textbf{They are optional, so please don't submit anything for them}.

\begin{itemize}
\item 6.6.2-4, 6.6.6, 6.6.9, 6.6.10
\end{itemize}

\pagebreak
\section{Linear Models (Programming)}

In this problem, you will be finding models for the cost of homes in California based on 1990 census data using multiple regression.
This is very similar to the example given in the section ``Multiple Regression in Practice'' from the text so please make sure to read this example if you want additional guidance.

The objective of this problem will not be implementing model fitting (as is the case for the example from the text).
This will be implemented for you via a single call to \texttt{numpy.linalg.lstsq}.
Rather, your primary objective is to build design matrices for linear, quadratic, and cubic functions.
You can use any function in NumPy we've seen in this course, but it may be useful to look at the following functions before you get started:
\begin{itemize}
\item \texttt{np.ones}
\item \texttt{np.column\_stack}
\item \texttt{np.linalg.norm}
\item Recall that \texttt{a[:,i]} is the \texttt{i}th column of \texttt{a}.
\end{itemize}
You are given starter code in the file \texttt{hw12prog.py}.
\textbf{Do not change the name of this file when you submit.}
Also don't change the names of any functions included in the starter code.
\textbf{The only changes you should make are to fill in the provided TODO items.}
In particular, you cannot change the imports to the file.
You may also notice that this file depends on scikit-learn.
\textbf{Please verify early that you can work with this dependency.}
If you set everything up for Homework 10, then this should require no additional work.

There are four function you need to fill in.
\begin{itemize}
\item \texttt{distance}, which calculates the distance between two vectors in $\R^n$, represented as 1D NumPy arrays.
\item \texttt{linear\_design\_matrix}, which builds the design matrix for simple multiple regression, i.e., for finding a model of the form
  \begin{displaymath}
    f(x_1, \dots, x_n) = \beta_0 + \sum_{1 \leq i \leq n} \beta_i x_i
  \end{displaymath}
  This matrix should be identical to the one in the text.
  The independent variables are given to you as a matrix, where each row represent a datapoint.
  The dataset has 8 independent variables, so the input \texttt{ind\_vars} is a 2D NumPy array with 8 columns, and the design matrix you return on the input \texttt{ind\_vars} should have 9 columns.
\item \texttt{quadratic\_design\_matrix}, which builds the design matrix for multiple regression with a quadratic modeling function, i.e.,
  \begin{displaymath}
    f(x_1, \dots, x_n) = \beta_0 + \sum_{1 \leq i \leq n} \beta_i x_i+ \sum_{1 \leq i \leq j \leq n} \beta_{ij} x_ix_j
  \end{displaymath}
  This will require adding many new columns; the design matrix you return on the input \texttt{ind\_vars} should have 45 columns.
\item \texttt{cubic\_design\_matrix}, which builds the design matrix for multiple regression with a cubic modeling function, i.e.,
  \begin{displaymath}
    f(x_1, \dots, x_n) = \beta_0 + \sum_{1 \leq i \leq n} \beta_i x_i + \sum_{1 \leq i \leq j \leq n} \beta_{ij} x_ix_j + \sum_{1 \leq i \leq j \leq k \leq n} \beta_{ijk} x_ix_jx_k
  \end{displaymath}
  The design matrix you return on the input \texttt{ind\_vars} should have 165 columns.
  As a hint, note that many of the columns you have to add are the same ones you added in the previous function; don't redo your work.
\end{itemize}
When you run the file, you should see a small report on the data and three error calculations for each kind of model.
If you've done everything correctly, your errors should be around 104, 93, and 86 for linear, quadratic, and cubic functions, respectively (note that the error goes down as the models become more complex).
There is also some commented-out code for graphing the predictions against the actual values (as in the text).
I highly recommend running this to see how the prediction accuracy ``looks'' for each model, but you don't have to submit anything for this.

You will upload a single file \texttt{hw12prog.py} to Gradescope, where you can verify that it passes some (but not all) autograder tests.
\end{document}
